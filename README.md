# Neural-networks
These 2 notebooks are my attempts at creating a 6 hidden layer NN with parametric ReLU as activation for each hidden layer. 

One of these has a shared alpha, while the other is a channel-wise implementation. 
